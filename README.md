![Texto alternativo](https://universidadeuropea.com/resources/media/images/universidad-europea-logo_poc9mEM.2e16d0ba.fill-767x384.png)
# Master en Data Science e Inteligencia Artificial
### Explainable AI (XAI)

El objetivo prioritario de este proyecto es aplicar varios frameworks de Inteligencia Artificial Explicable (XAI) a modelos de Machine Learning (ML) en diferentes dominios y contextos. Mejorar la interpretabilidad y la transparencia de estos, permitiendo a los usuarios comprender cómo se toman las decisiones y proporcionando explicaciones claras y comprensibles sobre el razonamiento detrás de esas decisiones. Esto es crucial para abordar la "caja negra" de los modelos de ML y fomentar la confianza y aceptación en su uso en aplicaciones críticas como la medicina, la seguridad y las finanzas.

## Autores
- Carlos Palomino Toro
- Carmen Escribano Rodríguez
- Carlos López Barbera
- Javier Guzmán Carneros Ladrón de Guevara



## Resumen del Prototipo Funcional 

En este proyecto se pretende proporcionar explicabilidad a dos algoritmos de Machine Learning no interpretables, también llamados ‘de caja negra’, de un modo inteligible y sencillo, de forma que sea un concepto accesible para un público sin preparación técnica en el campo, demostrando así la propia comprensión sobre el asunto y el estado del arte del mismo.

Para ello, se aplicarán tres frameworks de Model Unboxing de XAI sobre dos modelos de Machine Learning:
- Modelo de clasificación de imágenes utilizando el conjunto de datos MNIST de imágenes de dígitos numéricos. Lista de los modelos de aprendizaje interpretable aplicados al modelo de clasificación de imágenes. 
  - [![Video demostrativo del modelo de aprendizaje Integrated Gradients](https://ejemplo.com/imagen.png)](https://drive.google.com/file/d/1s4pwuNxYYjYgOyuU3BdnU7uqwtMqgqsd/view?usp=sharing)
  - [![Video demostrativo del modelo interpretable SHAP](https://ejemplo.com/imagen.png)](https://drive.google.com/file/d/11dG93dsoTk4nSjA4gLcxLKVN59lJHx54/view?usp=drive_link)
- Un modelo de supervivencia de pasajeros del conjunto de datos de Kaggle Titanic.

Finalmente, se evaluarán los modelos atendiendo, más que a la precisión de los mismos, a su interpretabilidad, y se compararán los resultados obtenidos por los distintos métodos y frameworks para obtener conclusiones.


