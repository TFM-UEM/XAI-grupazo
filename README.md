![Texto alternativo](https://universidadeuropea.com/resources/media/images/universidad-europea-logo_poc9mEM.2e16d0ba.fill-767x384.png)
# Master en Data Science e Inteligencia Artificial
### Explainable AI (XAI)

El objetivo prioritario de este proyecto es aplicar varios frameworks de Inteligencia Artificial Explicable (XAI) a modelos de Machine Learning (ML) en diferentes dominios y contextos. Mejorar la interpretabilidad y la transparencia de estos, permitiendo a los usuarios comprender cómo se toman las decisiones y proporcionando explicaciones claras y comprensibles sobre el razonamiento detrás de esas decisiones. Esto es crucial para abordar la "caja negra" de los modelos de ML y fomentar la confianza y aceptación en su uso en aplicaciones críticas como la medicina, la seguridad y las finanzas.

## Autores
- Carlos Palomino Toro
- Carmen Escribano Rodríguez
- Carlos López Barbera
- Javier Guzmán Carneros Ladrón de Guevara



## Resumen del Prototipo Funcional 

En este proyecto se pretende proporcionar explicabilidad a dos algoritmos de Machine Learning no interpretables, también llamados ‘de caja negra’, de un modo inteligible y sencillo, de forma que sea un concepto accesible para un público sin preparación técnica en el campo, demostrando así la propia comprensión sobre el asunto y el estado del arte del mismo. 

Para ello, se aplicarán tres frameworks de Model Unboxing de XAI al modelo de supervivencia de pasajeros del conjunto de datos de Kaggle Titanic.
- mmm

Finalmente, se evaluarán los modelos atendiendo, más que a la precisión de los mismos, a su interpretabilidad, y se compararán los resultados obtenidos por los distintos métodos y frameworks para obtener conclusiones.


